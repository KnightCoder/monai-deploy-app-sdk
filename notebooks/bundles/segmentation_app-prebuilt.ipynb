{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Segmentation App with MONAI Deploy App SDK\n",
    "\n",
    "This tutorial shows how to create an organ segmentation application for a PyTorch model that has been trained with MONAI and packaged into a MONAI bundle. This is derived form the segmentation app tutorial notebook.\n",
    "\n",
    "### Setup environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade monai-deploy-app-sdk\n",
    "%pip install monai # for MONAI transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download/Extract ai_spleen_seg_data from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /home/localek10/miniconda3/envs/deploy/lib/python3.9/site-packages (4.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/localek10/miniconda3/envs/deploy/lib/python3.9/site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: requests[socks] in /home/localek10/miniconda3/envs/deploy/lib/python3.9/site-packages (from gdown) (2.27.1)\n",
      "Requirement already satisfied: tqdm in /home/localek10/miniconda3/envs/deploy/lib/python3.9/site-packages (from gdown) (4.64.0)\n",
      "Requirement already satisfied: six in /home/localek10/miniconda3/envs/deploy/lib/python3.9/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: filelock in /home/localek10/miniconda3/envs/deploy/lib/python3.9/site-packages (from gdown) (3.6.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/localek10/miniconda3/envs/deploy/lib/python3.9/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/localek10/miniconda3/envs/deploy/lib/python3.9/site-packages (from requests[socks]->gdown) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/localek10/miniconda3/envs/deploy/lib/python3.9/site-packages (from requests[socks]->gdown) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/localek10/miniconda3/envs/deploy/lib/python3.9/site-packages (from requests[socks]->gdown) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/localek10/miniconda3/envs/deploy/lib/python3.9/site-packages (from requests[socks]->gdown) (2.0.12)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/localek10/miniconda3/envs/deploy/lib/python3.9/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1GC_N8YQk_mOWN02oOzAU_2YDmNRWk--n\n",
      "To: /home/localek10/workspace/monai/monai-deploy-app-sdk/notebooks/bundles/ai_spleen_seg_data_updated_1203.zip\n",
      "100%|████████████████████████████████████████| 104M/104M [00:03<00:00, 26.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download ai_spleen_seg_data test data zip file\n",
    "!pip install gdown \n",
    "!gdown \"https://drive.google.com/uc?id=1GC_N8YQk_mOWN02oOzAU_2YDmNRWk--n\"\n",
    "\n",
    "# After downloading ai_spleen_seg_data zip file from the web browser or using gdown,\n",
    "!unzip -qo \"ai_spleen_seg_data_updated_1203.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Bundle From Torchscript Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p spleen_segmentation\n",
    "!mkdir -p spleen_segmentation/configs\n",
    "!mkdir -p spleen_segmentation/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/localek10/miniconda3/envs/deploy/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "obj=torch.jit.load(\"model.ts\")\n",
    "state=obj.state_dict()\n",
    "torch.save({k:v.clone().cpu() for k,v in state.items()},\"spleen_segmentation/models/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting spleen_segmentation/configs/metadata.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile spleen_segmentation/configs/metadata.json\n",
    "\n",
    "{\n",
    "    \"schema\": \"https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/meta_schema_20220324.json\",\n",
    "    \"version\": \"0.1.0\",\n",
    "    \"changelog\": { \"0.0.1\": \"initialize the model package structure\"},\n",
    "    \"monai_version\": \"0.8.0\",\n",
    "    \"pytorch_version\": \"1.10.0\",\n",
    "    \"numpy_version\": \"1.21.2\",\n",
    "    \"optional_packages_version\": {    },\n",
    "    \"network_def\": {\n",
    "        \"_target_\": \"UNet\",\n",
    "        \"spatial_dims\": 3,\n",
    "        \"in_channels\": 1,\n",
    "        \"out_channels\": 2,\n",
    "        \"channels\": [16, 32, 64, 128, 256],\n",
    "        \"strides\": [2, 2, 2, 2],\n",
    "        \"num_res_units\": 2,\n",
    "        \"norm\": \"batch\"\n",
    "    },\n",
    "    \"task\": \"Spleen Segmentation\",\n",
    "    \"description\": \"A pre-trained model for segmenting the spleen\",\n",
    "    \"authors\": \"MONAI team\",\n",
    "    \"copyright\": \"Copyright (c) MONAI Consortium\",\n",
    "    \"data_source\": \"Speen data from the Medical Segmentation Decathlon\",\n",
    "    \"data_type\": \"dicom\",\n",
    "    \"image_classes\": \"single channel data, intensity scaled to [0, 1]\",\n",
    "    \"label_classes\": \"single channel data, 0 is background, 1 is segmentation\",\n",
    "    \"pred_classes\": \"2 channel probability data\",\n",
    "    \"intended_use\": \"This is an example, not to be used for diagnostic purposes\",\n",
    "    \"network_data_format\": {\n",
    "        \"inputs\": {\n",
    "            \"image\": {\n",
    "                \"type\": \"image\",\n",
    "                \"format\": \"magnitude\",\n",
    "                \"num_channels\": 1,\n",
    "                \"spatial_shape\": [160, 160, 160],\n",
    "                \"dtype\": \"float32\",\n",
    "                \"value_range\": [],\n",
    "                \"is_patch_data\": true,\n",
    "                \"channel_def\": {\"0\": \"image\"}\n",
    "            }\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"pred\": {\n",
    "                \"type\": \"image\",\n",
    "                \"format\": \"segmentation\",\n",
    "                \"num_channels\": 2,\n",
    "                \"spatial_shape\": [160,160,160],\n",
    "                \"dtype\": \"float32\",\n",
    "                \"value_range\": [],\n",
    "                \"is_patch_data\": true,\n",
    "                \"channel_def\": {\n",
    "                    \"0\": \"background\",\n",
    "                    \"1\": \"foreground\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting spleen_segmentation/configs/inference.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile spleen_segmentation/configs/inference.json\n",
    "\n",
    "{\n",
    "    \"imports\": [\n",
    "        \"$import glob\",\n",
    "        \"$import os\"\n",
    "    ],\n",
    "    \"device\": \"$torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\",\n",
    "    \"ckpt_path\": \"./spleen_segmentation/models/model.pt\",\n",
    "    \"dataset_dir\": \"/workspace/data\",\n",
    "    \"datalist\": \"$list(sorted(glob.glob(@dataset_dir + '/*/*.nii')))\",\n",
    "    \"network_def\": {\n",
    "        \"_target_\": \"UNet\",\n",
    "        \"spatial_dims\": 3,\n",
    "        \"in_channels\": 1,\n",
    "        \"out_channels\": 2,\n",
    "        \"channels\": [16, 32, 64, 128, 256],\n",
    "        \"strides\": [2, 2, 2, 2],\n",
    "        \"num_res_units\": 2,\n",
    "        \"norm\": \"batch\"\n",
    "    },\n",
    "    \"network\": \"$@network_def.to(@device)\",\n",
    "    \"preprocessing\": {\n",
    "        \"_target_\": \"Compose\",\n",
    "        \"transforms\": [\n",
    "            {\n",
    "                \"_target_\": \"LoadImaged\",\n",
    "                \"keys\": \"image\"\n",
    "            },\n",
    "            {\n",
    "                \"_target_\": \"EnsureChannelFirstd\",\n",
    "                \"keys\": \"image\"\n",
    "            },\n",
    "            {\n",
    "                \"_target_\": \"Orientationd\",\n",
    "                \"keys\": \"image\",\n",
    "                \"axcodes\": \"RAS\"\n",
    "            },\n",
    "            {\n",
    "                \"_target_\": \"Spacingd\",\n",
    "                \"keys\": \"image\",\n",
    "                \"pixdim\": [1.0, 1.0, 1.0],\n",
    "                \"mode\": [\"bilinear\"],\n",
    "                \"align_cornders\": true\n",
    "            },\n",
    "            {\n",
    "                \"_target_\": \"ScaleIntensityRanged\",\n",
    "                \"keys\": \"image\",\n",
    "                \"a_min\":-57, \n",
    "                \"a_max\":164, \n",
    "                \"b_min\":0.0, \n",
    "                \"b_max\":1.0, \n",
    "                \"clip\": true\n",
    "            },\n",
    "            {\n",
    "                \"_target_\": \"EnsureTyped\",\n",
    "                \"keys\": \"image\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"_target_\": \"Dataset\",\n",
    "        \"data\": \"$[{'image': i} for i in @datalist]\",\n",
    "        \"transform\": \"@preprocessing\"\n",
    "    },\n",
    "    \"dataloader\": {\n",
    "        \"_target_\": \"DataLoader\",\n",
    "        \"dataset\": \"@dataset\",\n",
    "        \"batch_size\": 1,\n",
    "        \"shuffle\": false,\n",
    "        \"num_workers\": 0\n",
    "    },\n",
    "    \"inferer\": {\n",
    "        \"_target_\": \"SlidingWindowInferer\",\n",
    "        \"roi_size\": [160, 160, 160],\n",
    "        \"sw_batch_size\": 4,\n",
    "        \"device\": \"@device\"\n",
    "    },\n",
    "    \"postprocessing\": {\n",
    "        \"_target_\": \"Compose\",\n",
    "        \"transforms\": [\n",
    "            {\n",
    "                \"_target_\": \"Activationsd\",\n",
    "                \"keys\": \"pred\",\n",
    "                \"softmax\": true\n",
    "            },\n",
    "            {\n",
    "                \"_target_\": \"AsDiscreted\",\n",
    "                \"keys\": \"pred\",\n",
    "                \"argmax\": true\n",
    "            },\n",
    "            {\n",
    "                \"_target_\": \"Invertd\",\n",
    "                \"keys\": \"pred\",\n",
    "                \"orig_keys\": \"image\",\n",
    "                \"nearest_interp\": true,\n",
    "                \"transform\": \"@preprocessing\"\n",
    "            },\n",
    "            {\n",
    "                \"_target_\": \"SaveImaged\",\n",
    "                \"keys\": \"pred\",\n",
    "                \"output_dir\": \"output\",\n",
    "                \"output_postfix\": \"seg\",\n",
    "                \"output_dtype\": \"uint8\",\n",
    "                \"resample\": false\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"handlers\": [\n",
    "        {\n",
    "            \"_target_\": \"CheckpointLoader\",\n",
    "            \"_disabled_\": \"$not os.path.exists(@ckpt_path)\",\n",
    "            \"load_path\": \"@ckpt_path\",\n",
    "            \"load_dict\": {\"model\": \"@network\"}\n",
    "        }\n",
    "    ],\n",
    "    \"evaluator\": {\n",
    "        \"_target_\": \"SupervisedEvaluator\",\n",
    "        \"device\": \"@device\",\n",
    "        \"val_data_loader\": \"@dataloader\",\n",
    "        \"network\": \"@network\",\n",
    "        \"inferer\": \"@inferer\",\n",
    "        \"postprocessing\": \"@postprocessing\",\n",
    "        \"val_handlers\": \"@handlers\",\n",
    "        \"amp\": true\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-12 15:48:39,901 - INFO - --- input summary of monai.bundle.scripts.ckpt_export ---\n",
      "2022-05-12 15:48:39,901 - INFO - > net_id: 'network_def'\n",
      "2022-05-12 15:48:39,902 - INFO - > filepath: 'spleen_segmentation.ts'\n",
      "2022-05-12 15:48:39,902 - INFO - > meta_file: 'spleen_segmentation/configs/metadata.json'\n",
      "2022-05-12 15:48:39,902 - INFO - > config_file: 'spleen_segmentation/configs/inference.json'\n",
      "2022-05-12 15:48:39,902 - INFO - > ckpt_file: 'spleen_segmentation/models/model.pt'\n",
      "2022-05-12 15:48:39,902 - INFO - ---\n",
      "\n",
      "\n",
      "'dst' model updated: 148 of 148 variables.\n",
      "2022-05-12 15:48:40,441 - INFO - exported to TorchScript file: spleen_segmentation.ts.\n"
     ]
    }
   ],
   "source": [
    "!python  -m monai.bundle ckpt_export network_def \\\n",
    "    --filepath spleen_segmentation.ts \\\n",
    "    --ckpt_file spleen_segmentation/models/model.pt \\\n",
    "    --meta_file spleen_segmentation/configs/metadata.json \\\n",
    "    --config_file spleen_segmentation/configs/inference.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.deploy.core import Application, resource, IOType\n",
    "from monai.deploy.operators import BundleOperator, create_bundle_operator\n",
    "from monai.deploy.operators.dicom_data_loader_operator import DICOMDataLoaderOperator\n",
    "from monai.deploy.operators.dicom_seg_writer_operator import DICOMSegmentationWriterOperator\n",
    "from monai.deploy.operators.dicom_series_selector_operator import DICOMSeriesSelectorOperator\n",
    "from monai.deploy.operators.dicom_series_to_volume_operator import DICOMSeriesToVolumeOperator\n",
    "\n",
    "@resource(cpu=1, gpu=1, memory=\"7Gi\")\n",
    "class AISpleenSegApp(Application):\n",
    "    def compose(self):\n",
    "\n",
    "        study_loader_op = DICOMDataLoaderOperator()\n",
    "        series_selector_op = DICOMSeriesSelectorOperator()\n",
    "        series_to_vol_op = DICOMSeriesToVolumeOperator()\n",
    "        # Creates DICOM Seg writer with segment label name in a string list\n",
    "        dicom_seg_writer = DICOMSegmentationWriterOperator(seg_labels=[\"Spleen\"])\n",
    "\n",
    "        # Creates the model specific segmentation operator\n",
    "        print(self._context.model_path)\n",
    "        spleen_seg_op = create_bundle_operator(self._context.model_path, \"inference\",out_type=IOType.DISK)\n",
    "\n",
    "        # Creates the DAG by linking the operators\n",
    "        self.add_flow(study_loader_op, series_selector_op, {\"dicom_study_list\": \"dicom_study_list\"})\n",
    "        self.add_flow(series_selector_op, series_to_vol_op, {\"study_selected_series_list\": \"study_selected_series_list\"})\n",
    "        self.add_flow(series_to_vol_op, spleen_seg_op, {\"image\": \"image\"})\n",
    "\n",
    "        # self.add_flow(series_selector_op, dicom_seg_writer, {\"study_selected_series_list\": \"study_selected_series_list\"})\n",
    "        # self.add_flow(spleen_seg_op, dicom_seg_writer, {\"seg_image\": \"seg_image\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\n"
     ]
    },
    {
     "ename": "IOMappingError",
     "evalue": "The downstream operator(DummyOperator) has no input port with label 'image'. It should be one of ().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOMappingError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m app \u001b[38;5;241m=\u001b[39m \u001b[43mAISpleenSegApp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m app\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdcm\u001b[39m\u001b[38;5;124m\"\u001b[39m, output\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspleen_segmentation.ts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mAISpleenSegApp.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deploy/lib/python3.9/site-packages/monai/deploy/core/application.py:126\u001b[0m, in \u001b[0;36mApplication.__init__\u001b[0;34m(self, runtime_env, do_run, path)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_builder()\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Compose operators\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_run:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun(log_level\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mlog_level)\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mAISpleenSegApp.compose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_flow(study_loader_op, series_selector_op, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdicom_study_list\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdicom_study_list\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_flow(series_selector_op, series_to_vol_op, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudy_selected_series_list\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudy_selected_series_list\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries_to_vol_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspleen_seg_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_flow(series_selector_op, dicom_seg_writer, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudy_selected_series_list\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudy_selected_series_list\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_flow(spleen_seg_op, dicom_seg_writer, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseg_image\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseg_image\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "File \u001b[0;32m~/miniconda3/envs/deploy/lib/python3.9/site-packages/monai/deploy/core/application.py:264\u001b[0m, in \u001b[0;36mApplication.add_flow\u001b[0;34m(self, upstream_op, downstream_op, io_map)\u001b[0m\n\u001b[1;32m    262\u001b[0m                 input_labels\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(op_input_labels)))\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m IOMappingError(\n\u001b[1;32m    265\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe downstream operator(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdownstream_op\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has no input port with label \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt should be one of (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(op_input_labels)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m             )\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_flow(upstream_op, downstream_op, io_maps)\n",
      "\u001b[0;31mIOMappingError\u001b[0m: The downstream operator(DummyOperator) has no input port with label 'image'. It should be one of ()."
     ]
    }
   ],
   "source": [
    "app = AISpleenSegApp()\n",
    "\n",
    "app.run(input=\"dcm\", output=\"output\", model=\"spleen_segmentation.ts\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python [conda env:deploy]",
   "language": "python",
   "name": "conda-env-deploy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
