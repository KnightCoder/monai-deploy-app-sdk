{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying a MedNIST Classifier App with MONAI Deploy App SDK (Prebuilt Model)\n",
    "\n",
    "This tutorial demos the process of packaging up a trained model using MONAI Deploy App SDK into an artifact which can be run as a local program performing inference, a workflow job doing the same, and a Docker containerized workflow execution.\n",
    "\n",
    "In this tutorial, we will use a trained model and implement & package the inference application, executing the application locally.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone the github project (the latest version of the main branch only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'source'...\n",
      "remote: Enumerating objects: 287, done.\u001b[K\n",
      "remote: Counting objects: 100% (287/287), done.\u001b[K\n",
      "remote: Compressing objects: 100% (248/248), done.\u001b[K\n",
      "remote: Total 287 (delta 62), reused 125 (delta 25), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (287/287), 1.24 MiB | 9.07 MiB/s, done.\n",
      "Resolving deltas: 100% (62/62), done.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf source \\\n",
    " && git clone --branch main --depth 1 https://github.com/Project-MONAI/monai-deploy-app-sdk.git source \\\n",
    " && rm -rf source/.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mednist_classifier_monaideploy.py\n"
     ]
    }
   ],
   "source": [
    "!ls source/examples/apps/mednist_classifier_monaideploy/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install monai-deploy-app-sdk package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: monai-deploy-app-sdk in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (0.5.0)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from monai-deploy-app-sdk) (1.24.3)\n",
      "Requirement already satisfied: networkx>=2.4 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from monai-deploy-app-sdk) (3.1)\n",
      "Requirement already satisfied: colorama>=0.4.1 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from monai-deploy-app-sdk) (0.4.6)\n",
      "Requirement already satisfied: typeguard~=2.12.1 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from monai-deploy-app-sdk) (2.12.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade monai-deploy-app-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install necessary packages for the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: monai in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (1.2.0)\n",
      "Requirement already satisfied: Pillow in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (9.5.0)\n",
      "Requirement already satisfied: torch>=1.9 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from monai) (2.0.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from monai) (1.24.3)\n",
      "Requirement already satisfied: filelock in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from torch>=1.9->monai) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from torch>=1.9->monai) (4.6.3)\n",
      "Requirement already satisfied: sympy in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from torch>=1.9->monai) (1.12)\n",
      "Requirement already satisfied: networkx in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from torch>=1.9->monai) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from torch>=1.9->monai) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from torch>=1.9->monai) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from torch>=1.9->monai) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from torch>=1.9->monai) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from torch>=1.9->monai) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from torch>=1.9->monai) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from torch>=1.9->monai) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from torch>=1.9->monai) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from torch>=1.9->monai) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from torch>=1.9->monai) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from torch>=1.9->monai) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from torch>=1.9->monai) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from torch>=1.9->monai) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9->monai) (68.0.0)\n",
      "Requirement already satisfied: wheel in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9->monai) (0.40.0)\n",
      "Requirement already satisfied: cmake in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.9->monai) (3.26.4)\n",
      "Requirement already satisfied: lit in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.9->monai) (16.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from jinja2->torch>=1.9->monai) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from sympy->torch>=1.9->monai) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install monai Pillow  # for MONAI transforms and Pillow\n",
    "!python -c \"import pydicom\" || pip install -q \"pydicom>=1.4.2\"\n",
    "!python -c \"import highdicom\" || pip install -q \"highdicom>=0.18.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download/Extract mednist_classifier_data.zip from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (4.7.1)\n",
      "Requirement already satisfied: filelock in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from gdown) (3.12.2)\n",
      "Requirement already satisfied: requests[socks] in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from gdown) (2.31.0)\n",
      "Requirement already satisfied: six in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from gdown) (4.65.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from beautifulsoup4->gdown) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from requests[socks]->gdown) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from requests[socks]->gdown) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from requests[socks]->gdown) (2023.5.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1yJ4P-xMNEfN6lIOq_u6x1eMAq1_MJu-E\n",
      "From (redirected): https://drive.google.com/uc?id=1yJ4P-xMNEfN6lIOq_u6x1eMAq1_MJu-E&confirm=t&uuid=988a29af-f32d-40a3-a50c-5ccda9b74d52\n",
      "To: /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/mednist_classifier_data.zip\n",
      "100%|██████████████████████████████████████| 28.6M/28.6M [00:00<00:00, 80.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download mednist_classifier_data.zip\n",
    "!pip install gdown \n",
    "!gdown \"https://drive.google.com/uc?id=1yJ4P-xMNEfN6lIOq_u6x1eMAq1_MJu-E\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  mednist_classifier_data.zip\n",
      " extracting: classifier.zip          \n",
      " extracting: input/AbdomenCT_007000.jpeg  \n"
     ]
    }
   ],
   "source": [
    "# After downloading mednist_classifier_data.zip from the web browser or using gdown,\n",
    "!unzip -o \"mednist_classifier_data.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package app (creating MAP Docker image)\n",
    "\n",
    "This assumes that nvidia docker is installed in the local machine.\n",
    "\n",
    "Please see https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker to install nvidia-docker2.\n",
    "\n",
    "Use `-l DEBUG` option to see progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building MONAI Application Package... -\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                                         \n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.1s (2/2)                                                         \n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.1s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.55kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 1.11kB                                        0.0s\n",
      "\u001b[0m\u001b[?25\\\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (4/19)                                                        \n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.1s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.55kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 1.11kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for nvcr.io/nvidia/pytorch:22.08-py3          0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/15] FROM nvcr.io/nvidia/pytorch:22.08-py3                          0.0s\n",
      "\u001b[0m => [internal] load build context                                          0.1s\n",
      " => => transferring context: 23B                                           0.1s\n",
      "\u001b[?25|\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.4s (4/19)                                                        \n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.1s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.55kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 1.11kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for nvcr.io/nvidia/pytorch:22.08-py3          0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/15] FROM nvcr.io/nvidia/pytorch:22.08-py3                          0.0s\n",
      "\u001b[0m => [internal] load build context                                          0.2s\n",
      "\u001b[34m => => transferring context: 29.04MB                                       0.2s\n",
      "\u001b[0m\u001b[?25/\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.6s (20/20)                                                       \n",
      "\u001b[34m => [internal] load metadata for nvcr.io/nvidia/pytorch:22.08-py3          0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/15] FROM nvcr.io/nvidia/pytorch:22.08-py3                          0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.3s\n",
      "\u001b[0m\u001b[34m => => transferring context: 29.04MB                                       0.2s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/15] RUN apt update      && apt upgrade -y --no-install-rec  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/15] RUN pip install --no-cache-dir --upgrade setuptools==5  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/15] RUN mkdir -p /etc/monai/      && mkdir -p /opt/monai/   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/15] RUN mkdir -p /opt/monai/models                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/15] COPY ./models /opt/monai/models                         0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/15] COPY ./pip/requirements.txt /opt/monai/app/requirement  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/15] RUN curl https://globalcdn.nuget.org/packages/monai.de  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/15] RUN pip install --no-cache-dir --user -r /opt/monai/ap  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/15] COPY ./monai-deploy-app-sdk /root/.local/lib/python3.8  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/15] RUN echo \"User site package location: $(python3 -m sit  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/15] COPY ./map/app.json /etc/monai/                         0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/15] COPY ./map/pkg.json /etc/monai/                         0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/15] COPY ./app /opt/monai/app                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/15] WORKDIR /var/monai/                                     0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:b29c06a2b9f52c65a2efa317721ffaf62bcd984b3a9b4  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/mednist_app:latest                      0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.6s (20/20) FINISHED                                              \n",
      "\u001b[34m => [internal] load build definition from dockerfile                       0.1s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.55kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 1.11kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for nvcr.io/nvidia/pytorch:22.08-py3          0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/15] FROM nvcr.io/nvidia/pytorch:22.08-py3                          0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.3s\n",
      "\u001b[0m\u001b[34m => => transferring context: 29.04MB                                       0.2s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/15] RUN apt update      && apt upgrade -y --no-install-rec  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/15] RUN pip install --no-cache-dir --upgrade setuptools==5  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/15] RUN mkdir -p /etc/monai/      && mkdir -p /opt/monai/   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/15] RUN mkdir -p /opt/monai/models                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/15] COPY ./models /opt/monai/models                         0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/15] COPY ./pip/requirements.txt /opt/monai/app/requirement  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/15] RUN curl https://globalcdn.nuget.org/packages/monai.de  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/15] RUN pip install --no-cache-dir --user -r /opt/monai/ap  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/15] COPY ./monai-deploy-app-sdk /root/.local/lib/python3.8  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/15] RUN echo \"User site package location: $(python3 -m sit  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/15] COPY ./map/app.json /etc/monai/                         0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/15] COPY ./map/pkg.json /etc/monai/                         0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/15] COPY ./app /opt/monai/app                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/15] WORKDIR /var/monai/                                     0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:b29c06a2b9f52c65a2efa317721ffaf62bcd984b3a9b4  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/mednist_app:latest                      0.0s\n",
      "\u001b[0m\u001b[?25Done\n",
      "[2023-06-22 18:58:52,674] [INFO] (app_packager) - Successfully built mednist_app:latest\n"
     ]
    }
   ],
   "source": [
    "!monai-deploy package \"source/examples/apps/mednist_classifier_monaideploy/mednist_classifier_monaideploy.py\" \\\n",
    "    --tag mednist_app:latest \\\n",
    "    --model classifier.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the app with docker image and input file locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dependencies...\n",
      "--> Verifying if \"docker\" is installed...\n",
      "\n",
      "--> Verifying if \"mednist_app:latest\" is available...\n",
      "\n",
      "Checking for MAP \"mednist_app:latest\" locally\n",
      "\"mednist_app:latest\" found.\n",
      "\n",
      "Reading MONAI App Package manifest...\n",
      "\u001b[sPreparing to copy...\u001b[?25l\u001b[u\u001b[2KCopying from container - 0B\u001b[?25h\u001b[u\u001b[2KSuccessfully copied 2.05kB to /tmp/tmpmkwgjelc/app.json\n",
      "\u001b[sPreparing to copy...\u001b[?25l\u001b[u\u001b[2KCopying from container - 0B\u001b[?25h\u001b[u\u001b[2KSuccessfully copied 2.05kB to /tmp/tmpmkwgjelc/pkg.json\n",
      "--> Verifying if \"nvidia-docker\" is installed...\n",
      "\n",
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n",
      "\u001b[34mGoing to initiate execution of operator LoadPILOperator\u001b[39m\n",
      "\u001b[32mExecuting operator LoadPILOperator \u001b[33m(Process ID: 1, Operator ID: d44638d2-6c5a-4263-9bc3-b95b72ea9f6c)\u001b[39m\n",
      "\u001b[34mDone performing execution of operator LoadPILOperator\n",
      "\u001b[39m\n",
      "\u001b[34mGoing to initiate execution of operator MedNISTClassifierOperator\u001b[39m\n",
      "\u001b[32mExecuting operator MedNISTClassifierOperator \u001b[33m(Process ID: 1, Operator ID: d1d5ef17-337a-437e-a37c-fa28f536cc64)\u001b[39m\n",
      "/root/.local/lib/python3.8/site-packages/monai/utils/deprecate_utils.py:111: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. It will be removed in version 1.3. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead with `channel_dim='no_channel'`.\n",
      "  warn_deprecated(obj, msg, warning_category)\n",
      "AbdomenCT\n",
      "\u001b[34mDone performing execution of operator MedNISTClassifierOperator\n",
      "\u001b[39m\n",
      "\u001b[34mGoing to initiate execution of operator DICOMTextSRWriterOperator\u001b[39m\n",
      "\u001b[32mExecuting operator DICOMTextSRWriterOperator \u001b[33m(Process ID: 1, Operator ID: 4f3027d2-8560-49f4-b13e-bef12cb25ba7)\u001b[39m\n",
      "/root/.local/lib/python3.8/site-packages/pydicom/valuerep.py:443: UserWarning: Invalid value for VR UI: 'xyz'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.\n",
      "  warnings.warn(msg)\n",
      "[2023-06-23 01:59:03,988] [INFO] (root) - Finished writing DICOM instance to file /var/monai/output/1.2.826.0.1.3680043.8.498.96432985033199104308035433976543671623.dcm\n",
      "\u001b[34mDone performing execution of operator DICOMTextSRWriterOperator\n",
      "\u001b[39m\n",
      "[2023-06-23 01:59:03,989] [INFO] (monai.deploy.operators.dicom_text_sr_writer_operator.DICOMTextSRWriterOperator) - DICOM SOP instance saved in /var/monai/output/1.2.826.0.1.3680043.8.498.96432985033199104308035433976543671623.dcm\n"
     ]
    }
   ],
   "source": [
    "!monai-deploy run mednist_app:latest \"input\" \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"AbdomenCT\""
     ]
    }
   ],
   "source": [
    "!cat output/output.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing and Packaging Application with MONAI Deploy App SDK\n",
    "\n",
    "Based on the Torchscript model(`classifier.zip`), we will implement an application that process an input Jpeg image and write the prediction(classification) result as JSON file(`output.json`).\n",
    "\n",
    "In our inference application, we will define two operators:\n",
    "\n",
    "1. `LoadPILOperator` - Load a JPEG image from the input path and pass the loaded image object to the next operator.\n",
    "    - This Operator does similar job with `LoadImage(image_only=True)` transform in *train_transforms*, but handles only one image.\n",
    "    - **Input**: a file path ([`DataPath`](/modules/_autosummary/monai.deploy.core.domain.DataPath))\n",
    "    - **Output**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "2. `MedNISTClassifierOperator` - Pre-transform the given image by using MONAI's `Compose` class, feed to the Torchscript model (`classifier.zip`), and write the prediction into JSON file(`output.json`)\n",
    "    - Pre-transforms consist of three transforms -- `AddChannel`, `ScaleIntensity`, and `EnsureType`.\n",
    "    - **Input**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "    - **Output**: a folder path that the prediction result(`output.json`) would be written ([`DataPath`](/modules/_autosummary/monai.deploy.core.domain.DataPath))\n",
    "\n",
    "The workflow of the application would look like this.\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/1928522/133868503-46671f0a-7741-4f9d-aefa-83e95e9a5f84.png\" alt=\"Workflow\" style=\"width: 600px;margin-left:auto;margin-right:auto;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup imports\n",
    "\n",
    "Let's import necessary classes/decorators and define `MEDNIST_CLASSES`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai.deploy.core as md\n",
    "from monai.deploy.core import (\n",
    "    Application,\n",
    "    DataPath,\n",
    "    ExecutionContext,\n",
    "    Image,\n",
    "    InputContext,\n",
    "    IOType,\n",
    "    Operator,\n",
    "    OutputContext,\n",
    ")\n",
    "from monai.transforms import AddChannel, Compose, EnsureType, ScaleIntensity\n",
    "\n",
    "MEDNIST_CLASSES = [\"AbdomenCT\", \"BreastMRI\", \"CXR\", \"ChestCT\", \"Hand\", \"HeadCT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Operator classes\n",
    "\n",
    "#### LoadPILOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@md.input(\"image\", DataPath, IOType.DISK)\n",
    "@md.output(\"image\", Image, IOType.IN_MEMORY)\n",
    "@md.env(pip_packages=[\"pillow\"])\n",
    "class LoadPILOperator(Operator):\n",
    "    \"\"\"Load image from the given input (DataPath) and set numpy array to the output (Image).\"\"\"\n",
    "\n",
    "    def compute(self, op_input: InputContext, op_output: OutputContext, context: ExecutionContext):\n",
    "        import numpy as np\n",
    "        from PIL import Image as PILImage\n",
    "\n",
    "        input_path = op_input.get().path\n",
    "        if input_path.is_dir():\n",
    "            input_path = next(input_path.glob(\"*.*\"))  # take the first file\n",
    "\n",
    "        image = PILImage.open(input_path)\n",
    "        image = image.convert(\"L\")  # convert to greyscale image\n",
    "        image_arr = np.asarray(image)\n",
    "\n",
    "        output_image = Image(image_arr)  # create Image domain object with a numpy array\n",
    "        op_output.set(output_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MedNISTClassifierOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@md.input(\"image\", Image, IOType.IN_MEMORY)\n",
    "@md.output(\"output\", DataPath, IOType.DISK)\n",
    "@md.env(pip_packages=[\"monai\"])\n",
    "class MedNISTClassifierOperator(Operator):\n",
    "    \"\"\"Classifies the given image and returns the class name.\"\"\"\n",
    "\n",
    "    @property\n",
    "    def transform(self):\n",
    "        return Compose([AddChannel(), ScaleIntensity(), EnsureType()])\n",
    "\n",
    "    def compute(self, op_input: InputContext, op_output: OutputContext, context: ExecutionContext):\n",
    "        import json\n",
    "\n",
    "        import torch\n",
    "\n",
    "        img = op_input.get().asnumpy()  # (64, 64), uint8\n",
    "        image_tensor = self.transform(img)  # (1, 64, 64), torch.float64\n",
    "        image_tensor = image_tensor[None].float()  # (1, 1, 64, 64), torch.float32\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        image_tensor = image_tensor.to(device)\n",
    "\n",
    "        model = context.models.get()  # get a TorchScriptModel object\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image_tensor)\n",
    "\n",
    "        _, output_classes = outputs.max(dim=1)\n",
    "\n",
    "        result = MEDNIST_CLASSES[output_classes[0]]  # get the class name\n",
    "        print(result)\n",
    "\n",
    "        # Get output (folder) path and create the folder if not exists\n",
    "        output_folder = op_output.get().path\n",
    "        output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Write result to \"output.json\"\n",
    "        output_path = output_folder / \"output.json\"\n",
    "        with open(output_path, \"w\") as fp:\n",
    "            json.dump(result, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Application class\n",
    "\n",
    "Our application class would look like below.\n",
    "\n",
    "It defines `App` class inheriting `Application` class.\n",
    "\n",
    "`LoadPILOperator` is connected to `MedNISTClassifierOperator` by using `self.add_flow()` in `compose()` method of `App`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@md.resource(cpu=1, gpu=1, memory=\"1Gi\")\n",
    "class App(Application):\n",
    "    \"\"\"Application class for the MedNIST classifier.\"\"\"\n",
    "\n",
    "    def compose(self):\n",
    "        load_pil_op = LoadPILOperator()\n",
    "        classifier_op = MedNISTClassifierOperator()\n",
    "\n",
    "        self.add_flow(load_pil_op, classifier_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing app locally"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can execute the app in the Jupyter notebook. Before doing so, we also need to clean the output folder which was created by running the packaged containerizd app in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf output\n",
    "\n",
    "app = App()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mGoing to initiate execution of operator LoadPILOperator\u001b[39m\n",
      "\u001b[32mExecuting operator LoadPILOperator \u001b[33m(Process ID: 53782, Operator ID: 4c984de0-b54b-4db3-9f0a-a822923201df)\u001b[39m\n",
      "\u001b[34mDone performing execution of operator LoadPILOperator\n",
      "\u001b[39m\n",
      "\u001b[34mGoing to initiate execution of operator MedNISTClassifierOperator\u001b[39m\n",
      "\u001b[32mExecuting operator MedNISTClassifierOperator \u001b[33m(Process ID: 53782, Operator ID: ec2b6504-0853-4d22-912a-1890901d677e)\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages/monai/utils/deprecate_utils.py:111: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. It will be removed in version 1.3. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead with `channel_dim='no_channel'`.\n",
      "  warn_deprecated(obj, msg, warning_category)\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages/monai/data/meta_tensor.py:116: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return torch.as_tensor(x, *args, **_kwargs).as_subclass(cls)  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbdomenCT\n",
      "\u001b[34mDone performing execution of operator MedNISTClassifierOperator\n",
      "\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "app.run(input=\"input/AbdomenCT_007000.jpeg\", output=\"output\", model=\"classifier.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"AbdomenCT\""
     ]
    }
   ],
   "source": [
    "!cat output/output.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Once the application is verified inside Jupyter notebook, we can write the whole application as a file(`mednist_classifier_monaideploy.py`) by concatenating code above, then add the following lines:\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    App(do_run=True)\n",
    "```\n",
    "\n",
    "The above lines are needed to execute the application code by using `python` interpreter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mednist_classifier_monaideploy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mednist_classifier_monaideploy.py\n",
    "\n",
    "# Copyright 2021 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import monai.deploy.core as md  # 'md' stands for MONAI Deploy (or can use 'core' instead)\n",
    "from monai.deploy.core import (\n",
    "    Application,\n",
    "    DataPath,\n",
    "    ExecutionContext,\n",
    "    Image,\n",
    "    InputContext,\n",
    "    IOType,\n",
    "    Operator,\n",
    "    OutputContext,\n",
    ")\n",
    "from monai.transforms import AddChannel, Compose, EnsureType, ScaleIntensity\n",
    "\n",
    "MEDNIST_CLASSES = [\"AbdomenCT\", \"BreastMRI\", \"CXR\", \"ChestCT\", \"Hand\", \"HeadCT\"]\n",
    "\n",
    "\n",
    "@md.input(\"image\", DataPath, IOType.DISK)\n",
    "@md.output(\"image\", Image, IOType.IN_MEMORY)\n",
    "@md.env(pip_packages=[\"pillow\"])\n",
    "class LoadPILOperator(Operator):\n",
    "    \"\"\"Load image from the given input (DataPath) and set numpy array to the output (Image).\"\"\"\n",
    "\n",
    "    def compute(self, op_input: InputContext, op_output: OutputContext, context: ExecutionContext):\n",
    "        import numpy as np\n",
    "        from PIL import Image as PILImage\n",
    "\n",
    "        input_path = op_input.get().path\n",
    "        if input_path.is_dir():\n",
    "            input_path = next(input_path.glob(\"*.*\"))  # take the first file\n",
    "\n",
    "        image = PILImage.open(input_path)\n",
    "        image = image.convert(\"L\")  # convert to greyscale image\n",
    "        image_arr = np.asarray(image)\n",
    "\n",
    "        output_image = Image(image_arr)  # create Image domain object with a numpy array\n",
    "        op_output.set(output_image)\n",
    "\n",
    "\n",
    "@md.input(\"image\", Image, IOType.IN_MEMORY)\n",
    "@md.output(\"output\", DataPath, IOType.DISK)\n",
    "@md.env(pip_packages=[\"monai\"])\n",
    "class MedNISTClassifierOperator(Operator):\n",
    "    \"\"\"Classifies the given image and returns the class name.\"\"\"\n",
    "\n",
    "    @property\n",
    "    def transform(self):\n",
    "        return Compose([AddChannel(), ScaleIntensity(), EnsureType()])\n",
    "\n",
    "    def compute(self, op_input: InputContext, op_output: OutputContext, context: ExecutionContext):\n",
    "        import json\n",
    "\n",
    "        import torch\n",
    "\n",
    "        img = op_input.get().asnumpy()  # (64, 64), uint8\n",
    "        image_tensor = self.transform(img)  # (1, 64, 64), torch.float64\n",
    "        image_tensor = image_tensor[None].float()  # (1, 1, 64, 64), torch.float32\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        image_tensor = image_tensor.to(device)\n",
    "\n",
    "        model = context.models.get()  # get a TorchScriptModel object\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image_tensor)\n",
    "\n",
    "        _, output_classes = outputs.max(dim=1)\n",
    "\n",
    "        result = MEDNIST_CLASSES[output_classes[0]]  # get the class name\n",
    "        print(result)\n",
    "\n",
    "        # Get output (folder) path and create the folder if not exists\n",
    "        output_folder = op_output.get().path\n",
    "        output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Write result to \"output.json\"\n",
    "        output_path = output_folder / \"output.json\"\n",
    "        with open(output_path, \"w\") as fp:\n",
    "            json.dump(result, fp)\n",
    "\n",
    "\n",
    "@md.resource(cpu=1, gpu=1, memory=\"1Gi\")\n",
    "class App(Application):\n",
    "    \"\"\"Application class for the MedNIST classifier.\"\"\"\n",
    "\n",
    "    def compose(self):\n",
    "        load_pil_op = LoadPILOperator()\n",
    "        classifier_op = MedNISTClassifierOperator()\n",
    "\n",
    "        self.add_flow(load_pil_op, classifier_op)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    App(do_run=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this time, let's execute the app in the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mGoing to initiate execution of operator LoadPILOperator\u001b[39m\n",
      "\u001b[32mExecuting operator LoadPILOperator \u001b[33m(Process ID: 54338, Operator ID: f27632fd-d1a3-426c-89c8-5fe0cebb005c)\u001b[39m\n",
      "\u001b[34mDone performing execution of operator LoadPILOperator\n",
      "\u001b[39m\n",
      "\u001b[34mGoing to initiate execution of operator MedNISTClassifierOperator\u001b[39m\n",
      "\u001b[32mExecuting operator MedNISTClassifierOperator \u001b[33m(Process ID: 54338, Operator ID: 8750bdcb-dd92-4429-9bef-d7c95ab2bd14)\u001b[39m\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages/monai/utils/deprecate_utils.py:111: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. It will be removed in version 1.3. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead with `channel_dim='no_channel'`.\n",
      "  warn_deprecated(obj, msg, warning_category)\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages/monai/data/meta_tensor.py:116: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return torch.as_tensor(x, *args, **_kwargs).as_subclass(cls)  # type: ignore\n",
      "AbdomenCT\n",
      "\u001b[34mDone performing execution of operator MedNISTClassifierOperator\n",
      "\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "!python \"mednist_classifier_monaideploy.py\" -i \"input/AbdomenCT_007000.jpeg\" -o output -m \"classifier.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above command is same with the following command line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mGoing to initiate execution of operator LoadPILOperator\u001b[39m\n",
      "\u001b[32mExecuting operator LoadPILOperator \u001b[33m(Process ID: 54377, Operator ID: 59fd22d8-50e6-47c9-bef0-e045786f4ae1)\u001b[39m\n",
      "\u001b[34mDone performing execution of operator LoadPILOperator\n",
      "\u001b[39m\n",
      "\u001b[34mGoing to initiate execution of operator MedNISTClassifierOperator\u001b[39m\n",
      "\u001b[32mExecuting operator MedNISTClassifierOperator \u001b[33m(Process ID: 54377, Operator ID: e9508ffb-8568-47af-98b3-6d5d31606ead)\u001b[39m\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages/monai/utils/deprecate_utils.py:111: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. It will be removed in version 1.3. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead with `channel_dim='no_channel'`.\n",
      "  warn_deprecated(obj, msg, warning_category)\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv05/lib/python3.8/site-packages/monai/data/meta_tensor.py:116: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return torch.as_tensor(x, *args, **_kwargs).as_subclass(cls)  # type: ignore\n",
      "AbdomenCT\n",
      "\u001b[34mDone performing execution of operator MedNISTClassifierOperator\n",
      "\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "!monai-deploy exec \"mednist_classifier_monaideploy.py\" -i \"input/AbdomenCT_007000.jpeg\" -o output -m \"classifier.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"AbdomenCT\""
     ]
    }
   ],
   "source": [
    "!cat output/output.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
